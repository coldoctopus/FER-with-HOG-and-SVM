{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essential files from /src folder\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score , classification_report #calculate accuracy\n",
    "from hog import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"D:\\GitHub\\FER-with-HOG-and-SVM\\datasets/train\"     #change your path here\n",
    "data_train, label_train, data_test, label_test = preprocessing(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_data(data, labels):\n",
    "    #Generate input array X\n",
    "    X = np.array(data)\n",
    "\n",
    "    #Generate output array y\n",
    "    lbe = LabelEncoder()\n",
    "    lbe.fit(labels)\n",
    "    y = lbe.transform(labels)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly kernel\n",
    "X_train , y_train = _transform_data(data_train, label_train)\n",
    "X_test , y_test = _transform_data(data_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='poly', degree = 3, gamma= 0.1,C=75, coef0=1)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = metrics.classification_report(y_test, prediction, target_names=['anger', 'happy', 'neutral', 'sad', 'suprise'],output_dict=True)\n",
    "rp = pd.DataFrame(rp).transpose()\n",
    "rp.drop(\"support\",axis=1,inplace=True)\n",
    "rp.drop(\"macro avg\",axis=0,inplace=True)\n",
    "rp.drop(\"weighted avg\",axis=0,inplace=True)\n",
    "rp.drop(\"accuracy\",axis=0,inplace=True)\n",
    "rp = round(rp.iloc[0:]*100,2)\n",
    "rp\n",
    "\n",
    "# # note on metrics:\n",
    "# # precision: how often the model is correct when it predicts a class (true positives / (true positives + false positives))\n",
    "# high value => when model predicts a class, it is likely to be correct\n",
    "# # recall: how often the model predicts a class when it is actually that class (true positives / (true positives + false negatives))\n",
    "# high value => when the class is present, the model is likely to predict it\n",
    "# # f1: harmonic mean of precision and recall, useful when you want to balance both metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(title,data):\n",
    "    face = ['anger', 'happy', 'neutral', 'sad', 'suprise']\n",
    "\n",
    "    # Create a bar chart\n",
    "    bars = plt.bar(face, data, color=['red', 'lightgreen', 'yellow', 'gray', 'plum'])\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Expression')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.title(title)\n",
    "\n",
    "    for bar in bars:\n",
    "        val = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, val, round(val, 2), ha='center', va='bottom')\n",
    "    # Show the bar chart\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot(\"Precision\",rp.precision)\n",
    "show_plot(\"Recall\",rp.recall)\n",
    "show_plot(\"F1 Score\", rp['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_Matrix = confusion_matrix(y_test, prediction)\n",
    "confusion_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "acc_per_class = confusion_matrix.diagonal()\n",
    "apc = pd.DataFrame(index=['anger', 'happy', 'neutral', 'sad', 'suprise'],data=acc_per_class,columns=['Accuracy per class'])\n",
    "apc = round(apc.iloc[0:]*100,2)\n",
    "show_plot(\"Accuracy per class\", apc['Accuracy per class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, prediction)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [True, True])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "#from 0 to 4: anger, happy, neutral, sad, suprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
